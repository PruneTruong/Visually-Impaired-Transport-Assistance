1. follow steps on website to install the Object detection API: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md

2. in tensorflow/models/research/object_detection/protos/ssd.proto, remove line 87

3. watch out; if using IDE, remember to add to PYTHONPATH the following: 
PYTHONPATH=$PYTHONPATH:<path-to-tensorflow/models/research>:<path-to-tensorflow/models/research/slim>

4. added try/except in create_coco_tf_record.py to be able to skip images not in datafile.:
      try:
          if idx % 100 == 0:
            tf.logging.info('On image %d of %d', idx, len(images))
          annotations_list = annotations_index[image['id']]
          _, tf_example, num_annotations_skipped = create_tf_example(
              image, annotations_list, image_dir, category_index, include_masks)
          total_num_annotations_skipped += num_annotations_skipped
          writer.write(tf_example.SerializeToString())
      except tf.errors.NotFoundError:
          tf.logging.warning(' Image {} not found in data file.' .format(idx))

note: might implement another solution to generate dataset: see script here, and iterate over labelfile & img.: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md 

CLUSTER
1/ installed pip
- from local computer: scp -r Visually-impaired... user@host:
- delete folder from computer env
- launched: source utils/env_cluster.sh to create virtual env
- activate virtual env: source env/bin/activate
- module load python_gpu/3.6.4 protobuf
- make makefile install_gpu (note: might need to remove --user (?))
- cd env/lib/python/site-packages/tensorflow, git clone https://github.com/tensorflow/models.git to have the object_detection API
- go to models/research/object_detection, and apply patch for dataset creation: git apply <path to dataset_coco_creation.patch>
- go to research and do: protoc object_detection/protos/*.proto --python_out=.
- export dependencies / add into .bashrc: export PYTHONPATH=$PYTHONPATH:<path-to-tensorflow/models/research>:<path-to-tensorflow/models/research/slim>
note: also added "$RESEARCH" variable for ease.
- go to Vis...: launch batch job with command: XXX

2/ Tensorboard:
- either log off, or before creating ssh connection do:
ssh -L port-machine:ip:port-remote user@host. eg. ssh -L 16006:127.0.0.1:6008 lna@login.leonhard.ethz.ch
- module load python_cpu
- `tensorboard --logdir=xxxx, --port=port-remote`


LOG:
note: modified eval.proto. see if create new patch or not

